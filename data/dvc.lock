schema: '2.0'
stages:
  prepare_data@TFTokenizer:
    cmd: python src/prepare.py --preprocessor=TFTokenizer
    deps:
    - path: data/raw/train.csv
      md5: f147942c91d00d754503775341d13682
      size: 987712
    - path: src/prepare.py
      md5: ed929904f1719748349173d3341dccd3
      size: 3767
    outs:
    - path: data/prepared/TFTokenizer/labels.json
      md5: 76e06f8528ff37525b0f13d4dc8d6d0e
      size: 22860
    - path: data/prepared/TFTokenizer/preproc.joblib
      md5: 468fbf684fd1995535089a2b2f447d43
      size: 669288
    - path: data/prepared/TFTokenizer/texts.json
      md5: 991dfd263b8f099134356763e119a105
      size: 523430
  prepare_data@SKCountVectorizer:
    cmd: python src/prepare.py --preprocessor=SKCountVectorizer
    deps:
    - path: data/raw/train.csv
      md5: f147942c91d00d754503775341d13682
      size: 987712
    - path: src/prepare.py
      md5: ed929904f1719748349173d3341dccd3
      size: 3767
    outs:
    - path: data/prepared/SKCountVectorizer/labels.json
      md5: 76e06f8528ff37525b0f13d4dc8d6d0e
      size: 22860
    - path: data/prepared/SKCountVectorizer/preproc.joblib
      md5: cc160c69d6aeb21966bbbe5a31acb819
      size: 223216
    - path: data/prepared/SKCountVectorizer/texts.json
      md5: 991dfd263b8f099134356763e119a105
      size: 523430
