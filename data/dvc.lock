schema: '2.0'
stages:
  prepare_data@TFTokenizer:
    cmd: python src/prepare.py --preprocessor=TFTokenizer
    deps:
    - path: data/raw/train.csv
      md5: f147942c91d00d754503775341d13682
      size: 987712
    - path: src/prepare.py
      md5: 0837c258910e9c2e0b9b57ff4dc20583
      size: 4951
    outs:
    - path: data/prepared/TFTokenizer/labels.json
      md5: 9b82a809810ad0411147c95d06a5c946
      size: 22869
    - path: data/prepared/TFTokenizer/preproc.joblib
      md5: 810de9ee4290905b260cc07790f79dd1
      size: 669288
    - path: data/prepared/TFTokenizer/texts.json
      md5: 5afaf5998a346dd53dd6e7fd288c13cb
      size: 523439
  prepare_data@SKCountVectorizer:
    cmd: python src/prepare.py --preprocessor=SKCountVectorizer
    deps:
    - path: data/raw/train.csv
      md5: f147942c91d00d754503775341d13682
      size: 987712
    - path: src/prepare.py
      md5: c31558778c4c025cdbf1016ab0916e1f
      size: 3913
    outs:
    - path: data/prepared/SKCountVectorizer/labels.json
      md5: 76e06f8528ff37525b0f13d4dc8d6d0e
      size: 22860
    - path: data/prepared/SKCountVectorizer/preproc.joblib
      md5: 1d4fe03ec78190fc4432196b1a552583
      size: 223216
    - path: data/prepared/SKCountVectorizer/texts.json
      md5: 991dfd263b8f099134356763e119a105
      size: 523430
