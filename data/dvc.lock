schema: '2.0'
stages:
  prepare_data@TFTokenizer:
    cmd: python src/prepare.py --preprocessor=TFTokenizer
    deps:
    - path: data/raw/train.csv
      md5: f147942c91d00d754503775341d13682
      size: 987712
    - path: src/prepare.py
      md5: 6084bd323f3ed1f258fea36f46c01868
      size: 4976
    outs:
    - path: data/prepared/TFTokenizer/labels.json
      md5: 9b82a809810ad0411147c95d06a5c946
      size: 22869
    - path: data/prepared/TFTokenizer/preproc.joblib
      md5: 0abbcc3a2583390ab6f363d233c788a7
      size: 667924
    - path: data/prepared/TFTokenizer/texts.json
      md5: 158c1657f6d3f1c0bcc3e69e1b815818
      size: 523215
  prepare_data@SKCountVectorizer:
    cmd: python src/prepare.py --preprocessor=SKCountVectorizer
    deps:
    - path: data/raw/train.csv
      md5: f147942c91d00d754503775341d13682
      size: 987712
    - path: src/prepare.py
      md5: 6084bd323f3ed1f258fea36f46c01868
      size: 4976
    outs:
    - path: data/prepared/SKCountVectorizer/labels.json
      md5: 9b82a809810ad0411147c95d06a5c946
      size: 22869
    - path: data/prepared/SKCountVectorizer/preproc.joblib
      md5: 9db0cdb0d67e5856d15b7c3154e54143
      size: 222716
    - path: data/prepared/SKCountVectorizer/texts.json
      md5: 158c1657f6d3f1c0bcc3e69e1b815818
      size: 523215
